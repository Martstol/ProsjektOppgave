\section{Tests}

TODO: Write about all the snow simulator configurations when doing these tests
Also write about what solvers were used by PETSc and which solver is used
by the default gpu snow simulator

TODO: When running the solver on the cpu the following command line arguments
are given: "\emph{-vec\_type standard -mat\_type aij}" and on the gpu:
"\emph{-vec\_type viennacl -mat\_type aijviennacl}".

The configuration options for the wind simulator allows for variation in the
external wind direction, speed and the resolution of the three dimensional wind
velocity field. For the scope of these tests only the resolution of the wind
velocity field is changed, while the external wind's speed and direction remains
unchanged for all tests. The resolution of the wind velocity field is denoted
as \{ x, y, z \}. The terrain used for the simulation tests is the height map of
Mount St. Helens with a size of 768x768. The external wind's speed is set to 1
and the direction is given by the unit vector \{1, 0, 0\}.

\subsection{Convergence Tests}

TODO: Write about the convergence

\subsection{Performance Tests}

\subsubsection{Time Distribution}

This test measures how the execution time of the wind simulation is distributed
between these key functions in the implementation:
\begin{description}
	\item[advect:] Performs the advection step of the wind simulation.
	\item[setupSolution:] Computes the right-hand side of the linear system.
	\item[setInitialGuess:] Sets the initial guess for the solver.
	\item[solve:] Solves the Poisson equation using a PETSc solver.
	\item[project:] Performs the projection step of the wind simulation.
	\item[windToGPU:] Moves the wind velocity field to texture memory for the
	snow particle simulation.
\end{description}

The solver chosen for this test is GMRES, this was specified with the command
line argument "\emph{-ksp\_type gmres}".

This test is performed for four different configurations for the resolution of
the wind velocity field:
\begin{description}
	\item[Configuration 1] $ \{ 32, 16, 32 \} $, the total number of internal
		nodes is 16384. Results are shown in figure \ref{fig:td_conf1}.
	\item[Configuration 2] $ \{ 64, 32, 64 \} $, the total number of internal
		nodes is 131072. Results are shown in figure \ref{fig:td_conf2}.
	\item[Configuration 3] $ \{ 128, 64, 128 \} $, the total number of internal
		nodes is 1048576. Results are shown in figure \ref{fig:td_conf3}.
	\item[Configuration 4] $ \{ 256, 128, 256 \} $, the total number of internal
		nodes is 8388608. Results are shown in figure \ref{fig:td_conf4}.
\end{description}

The results of the time distribution tests is the average execution time of each
key function after 100 frames of simulation.

\begin{figure}[ht]
	\center
	
	\begin{subfigure}{0.45\textwidth}
		\center
		\includegraphics[width=1.0\textwidth]{results/data/td_conf1_petsc_gpu}
		\caption{PETSc on the GPU with OpenCL.}
		\label{fig:td_conf1_petsc_gpu}
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\center
		\includegraphics[width=1.0\textwidth]{results/data/td_conf1_petsc_cpu}
		\caption{PETSc on the CPU.}
		\label{fig:td_conf1_petsc_cpu}
	\end{subfigure}
	\caption{Time distribution of the execution time of the key functions
			with configuration 1}
	\label{fig:td_conf1}
	
\end{figure}

\begin{figure}[ht]
	\center
	
	\begin{subfigure}{0.45\textwidth}
		\center
		\includegraphics[width=1.0\textwidth]{results/data/td_conf2_petsc_gpu}
		\caption{PETSc on the GPU with OpenCL.}
		\label{fig:td_conf2_petsc_gpu}
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\center
		\includegraphics[width=1.0\textwidth]{results/data/td_conf2_petsc_cpu}
		\caption{PETSc on the CPU.}
		\label{fig:td_conf2_petsc_cpu}
	\end{subfigure}
	\caption{Time distribution of the execution time of the key functions
			with configuration 2}
	\label{fig:td_conf2}
	
\end{figure}

\begin{figure}[ht]
	\center
	
	\begin{subfigure}{0.45\textwidth}
		\center
		\includegraphics[width=1.0\textwidth]{results/data/td_conf3_petsc_gpu}
		\caption{PETSc on the GPU with OpenCL.}
		\label{fig:td_conf3_petsc_gpu}
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\center
		\includegraphics[width=1.0\textwidth]{results/data/td_conf3_petsc_cpu}
		\caption{PETSc on the CPU.}
		\label{fig:td_conf3_petsc_cpu}
	\end{subfigure}
	\caption{Time distribution of the execution time of the key functions
			with configuration 3}
	\label{fig:td_conf3}
	
\end{figure}

\begin{figure}[ht]
	\center
	
	\begin{subfigure}{0.45\textwidth}
		\center
		\includegraphics[width=1.0\textwidth]{results/data/td_conf4_petsc_gpu}
		\caption{PETSc on the GPU with OpenCL.}
		\label{fig:td_conf4_petsc_gpu}
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\center
		\includegraphics[width=1.0\textwidth]{results/data/td_conf4_petsc_cpu}
		\caption{PETSc on the CPU.}
		\label{fig:td_conf4_petsc_cpu}
	\end{subfigure}
	\caption{Time distribution of the execution time of the key functions
			with configuration 4}
	\label{fig:td_conf4}
	
\end{figure}

As evident from these charts we can see that as the resolution of the wind
velocity field increases, the fraction of the wind simulation time spent solving
the Poisson equation remains roughly unchanged for the PETSc on CPU only
implementation, however when the GPU is utilized for the solver the fraction of
the simulation time spent solving the Poisson equation is reduced rapidly as
the computational power of the GPU is better utilized for larger problems because
of the GPU's parallel nature.

\subsection{Visual Results}

TODO: Show the windfield and pressure field and obstacle field (if I have time)
